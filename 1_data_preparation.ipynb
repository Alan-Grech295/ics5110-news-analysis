{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T08:54:57.983465Z",
     "start_time": "2025-12-07T08:54:48.846400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import itertools\n",
    "import logging\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Union, Any, Callable, Literal\n",
    "\n",
    "from pydantic.main import IncEx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "# from gensim.models import KeyedVectors\n",
    "import matplotlib.pyplot as plt\n",
    "# from anthropic import AnthropicFoundry, beta_tool\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "id": "967e254963ec671e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alang\\AppData\\Local\\Temp\\ipykernel_39148\\783871896.py:32: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\alang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\alang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T08:54:58.083663Z",
     "start_time": "2025-12-07T08:54:57.994367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load datasets as raw CSVs\n",
    "news_articles_df = pd.read_csv(\"data/local_news_articles.csv\")\n",
    "press_releases_df = pd.read_csv(\"data/police_press_releases.csv\")"
   ],
   "id": "96d7bc4a3fd10f1c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T08:54:58.144435Z",
     "start_time": "2025-12-07T08:54:58.092008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mapping = str.maketrans({\n",
    "    \"ċ\": \"c\",\n",
    "    \"Ċ\": \"C\",\n",
    "    \"ġ\": \"g\",\n",
    "    \"Ġ\": \"G\",\n",
    "    \"ħ\": \"h\",\n",
    "    \"Ħ\": \"H\",\n",
    "    \"ż\": \"z\",\n",
    "    \"Ż\": \"Z\",\n",
    "    \"“\": '\"',\n",
    "    \"”\": '\"',\n",
    "    \"‘\": \"'\",\n",
    "    \"’\": \"'\",\n",
    "    \"—\": \"-\",\n",
    "    \"–\": \"-\",\n",
    "    \"…\": \"...\",\n",
    "})\n",
    "\n",
    "def clean_articles(df: pd.DataFrame, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str).str.translate(mapping)\n",
    "    return df\n",
    "\n",
    "news_articles_df = clean_articles(news_articles_df, [\"title\", \"subtitle\", \"content\"])\n",
    "press_releases_df = clean_articles(press_releases_df, [\"title\", \"content\"])"
   ],
   "id": "cab8d8f36780746b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T08:55:13.621719Z",
     "start_time": "2025-12-07T08:54:58.150890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "people_subj = {\"man\", \"woman\", \"child\", \"driver\", \"motorist\", \"motorcyclist\", \"pedestrian\"}\n",
    "vehicles = {\"car\", \"motorcycle\", \"truck\", \"van\", \"bus\", \"bicycle\",\n",
    "            \"Audi\", \"BMW\", \"Chevrolet\", \"Citroen\", \"Dodge\", \"Fiat\", \"Ford\", \"Honda\", \"Hyundai\", \"Isuzu\",\n",
    "            \"Jaguar\", \"Jeep\", \"Kia\", \"Kymco\", \"Mercedes\", \"Mercedes-Benz\", \"Mini\", \"Mitsubishi\", \"Nissan\",\n",
    "            \"Peugeot\", \"Renault\", \"Skoda\", \"Subaru\", \"Suzuki\", \"Toyota\", \"Volkswagen\", \"VW\", \"Volvo\"}\n",
    "accident = {\"accident\", \"crash\", \"collision\"}\n",
    "injuries = {\"injure\", \"die\"}\n",
    "\n",
    "phrases = [\n",
    "    \"car crash\", \"traffic accident\", \"road accident\", \"collision\",\n",
    "    \"crashed\", \"crash\", \"hit by a car\", \"motorcycle accident\",\n",
    "    \"injured in a crash\", \"overturned\", \"run over\", \"lost control\"\n",
    "]\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "patterns = [nlp(text) for text in phrases]\n",
    "matcher.add(\"ACCIDENT_PATTERNS\", patterns)\n",
    "\n",
    "def refers_to_accident(text: str) -> bool:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    if len(matches) > 0:\n",
    "        return True\n",
    "\n",
    "    has_people = False\n",
    "    has_vehicles = False\n",
    "    has_accident = False\n",
    "    has_injury = False\n",
    "\n",
    "    for token in doc:\n",
    "        if token.lemma_ in people_subj:\n",
    "            has_people = True\n",
    "\n",
    "        if token.lemma_ in vehicles:\n",
    "            has_vehicles = True\n",
    "\n",
    "        if token.lemma_ in accident:\n",
    "            has_accident = True\n",
    "\n",
    "        if token.lemma_ in injuries:\n",
    "            has_injury = True\n",
    "\n",
    "        if has_people and has_vehicles and (has_accident or has_injury):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "non_related_news_article_ids = []\n",
    "\n",
    "for id, text in news_articles_df[[\"id\", \"content\"]].values:\n",
    "    is_accident = refers_to_accident(text)\n",
    "    if not is_accident:\n",
    "        non_related_news_article_ids.append(id)\n",
    "\n",
    "os.makedirs(\"data/intermediate\", exist_ok=True)\n",
    "\n",
    "non_related_news_article_df = news_articles_df[news_articles_df[\"id\"].isin(non_related_news_article_ids)]\n",
    "related_news_article_df = news_articles_df[~news_articles_df[\"id\"].isin(non_related_news_article_ids)]\n",
    "non_related_news_article_df.to_csv(\"data/intermediate/local_news_articles_exclusions.csv\", index=False)\n",
    "related_news_article_df.to_csv(\"data/intermediate/local_news_articles.csv\", index=False)"
   ],
   "id": "507144bfe0768b4c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T08:55:14.524619Z",
     "start_time": "2025-12-07T08:55:14.101515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "api_version = \"2025-01-01-preview\"\n",
    "\n",
    "endpoint = \"https://news-analysis-resource.openai.azure.com/openai/v1/\"\n",
    "\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=endpoint,\n",
    "    api_key=token_provider,\n",
    ")"
   ],
   "id": "bb25c1ae9683630d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T08:59:58.245969Z",
     "start_time": "2025-12-07T08:55:14.612293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NonAccidentIDs(BaseModel):\n",
    "    ids: List[int] = Field(description=\"A list of ids of news articles that are not accidents\")\n",
    "\n",
    "models = [(\"gpt-5-mini\", 50), (\"grok-4-fast-non-reasoning\", 50), (\"DeepSeek-R1-0528\", 20)]\n",
    "\n",
    "system_msg = \"\"\"\n",
    "You are a senior data scientist reviewing a semi-structured dataset of vehicle accidents news articles. The articles were obtained by simple web scraping (ex: on the tag of the article) which means that some articles do not refer to actual accidents (for example, they refer to new accident/traffic measures).\n",
    "\n",
    "Your job is to review the given accident CSV and return a list of news article IDs that do not refer to accidents.\n",
    "Be very critical! Any article which mentions a specific accident and provides details on it should not be removed.\n",
    "\n",
    "IMPORTANT: You MUST return the data by calling the `set_non_accident_ids` function.\n",
    "\n",
    "Do not return anything other than a function call.\n",
    "\"\"\"\n",
    "\n",
    "csv_prompt = lambda dataset_csv, start_rows, end_rows, total_rows: f\"\"\"\n",
    "MAKE SURE THAT THE RETURNED IDS EXIST IN THIS CSV!\n",
    "\n",
    "Accident CSV Data ({start_rows}-{end_rows}/{total_rows} rows):\n",
    "\n",
    "{dataset_csv}\n",
    "\"\"\"\n",
    "\n",
    "result_function = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"set_non_accident_ids\",\n",
    "        \"description\": \"Set the IDs of the news articles which do not refer to an accident\",\n",
    "        \"parameters\": NonAccidentIDs.model_json_schema()\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [result_function]\n",
    "\n",
    "tqdm.set_lock(threading.RLock())\n",
    "\n",
    "def process_model(model, num_rows_per_request, dataset_df: pd.DataFrame, system_prompt) -> set[int]:\n",
    "    total_ids = set()\n",
    "\n",
    "    with tqdm(range(0, len(dataset_df.index), num_rows_per_request), desc=f\"Querying {model}\", total=len(dataset_df.index), unit=\" rows\") as pbar:\n",
    "        i = 0\n",
    "        while i < len(dataset_df.index):\n",
    "            try:\n",
    "                start = i\n",
    "                end = min(i + num_rows_per_request, len(dataset_df.index))\n",
    "\n",
    "                df_section: pd.DataFrame = dataset_df.iloc[start:end]\n",
    "                df_section_csv = df_section.to_csv(index=False)\n",
    "\n",
    "                messages = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": system_prompt,\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": csv_prompt(df_section_csv, start + 1, end + 1, len(dataset_df.index)),\n",
    "                    }\n",
    "                ]\n",
    "\n",
    "                response = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    tools=tools,\n",
    "                    messages=messages,\n",
    "                )\n",
    "\n",
    "                result: NonAccidentIDs = NonAccidentIDs.model_validate_json(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "                for id in result.ids:\n",
    "                    if id not in dataset_df[\"id\"].values:\n",
    "                        raise ValueError(f\"ID {id} not in dataset\")\n",
    "\n",
    "                total_ids.update(result.ids)\n",
    "\n",
    "                pbar.update(end - start)\n",
    "                i += num_rows_per_request\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Failed to query {model}: {e}\")\n",
    "\n",
    "    return total_ids\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(models)) as executor:\n",
    "    futures = {\n",
    "        executor.submit(\n",
    "            process_model,\n",
    "            model,\n",
    "            num_rows_per_request,\n",
    "            related_news_article_df,\n",
    "            system_msg\n",
    "        ): model\n",
    "        for model, num_rows_per_request in models\n",
    "    }\n",
    "\n",
    "    model_ids = {}\n",
    "\n",
    "    for f in futures.keys():\n",
    "        result = f.result()\n",
    "        model_ids[futures[f]] = result\n",
    "\n",
    "    print({\n",
    "        model: list(sorted(ids)) for model, ids in model_ids.items()\n",
    "    })\n",
    "\n",
    "all_ids = list(model_ids.values())\n",
    "ids_union = all_ids[0].union(*all_ids[1:])\n",
    "\n",
    "related_news_article_df[related_news_article_df[\"id\"].isin(ids_union)].to_csv(\"data/intermediate/local_news_articles_llm_exclusions.csv\", index=False)\n",
    "related_news_article_df[related_news_article_df[\"id\"].isin(ids_union)].to_csv(\"data/intermediate/local_news_articles_llm_manual_exclusions.csv\", index=False)"
   ],
   "id": "c00e9ea8a57544a3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Querying grok-4-fast-non-reasoning:   0%|          | 0/242 [00:00<?, ? rows/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00f6fb42be6c4ec6a813732bdafbdf79"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Querying DeepSeek-R1-0528:   0%|          | 0/242 [00:00<?, ? rows/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9df6bd945824a719e975ca81f536630"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Querying gpt-5-mini:   0%|          | 0/242 [00:00<?, ? rows/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0ef6d85659f40168420b33fa075ec9f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpt-5-mini': [46, 370, 645, 695, 894, 1387, 2022, 3827, 467185, 493223, 493920, 496068, 496154], 'grok-4-fast-non-reasoning': [46, 287, 370, 645, 2022, 2092, 3604, 3699, 3809, 3823, 3827, 490929, 491047, 491118, 491371, 491380, 491437, 493920, 494102, 495320, 495942, 496154, 496206, 496362], 'DeepSeek-R1-0528': [46, 370, 645, 695, 894, 1352, 1387, 2022, 2092, 3535, 3827, 467108, 467185, 467297, 489424, 490206, 490685, 490742, 490929, 491047, 491118, 491371, 491380, 491437, 493212, 493223, 493920, 494102, 496068, 496154]}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Manually review LLM exclusions\n",
    "## Removed IDs\n",
    "- 3699\n",
    "- 1352\n",
    "- 370\n",
    "- 287\n",
    "- 489424\n",
    "- 491118\n",
    "- 491371\n",
    "- 494102\n",
    "- 495320 (inconclusive evidence)\n",
    "- 495942\n",
    "- 496362"
   ],
   "id": "b555b459dc1ee45f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T09:18:02.271184Z",
     "start_time": "2025-12-07T09:18:02.261338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "manual_ids = {3699, 1352, 370, 287, 489424, 491118, 491371, 494102, 495320, 495942, 496362}\n",
    "llm_manual_exclusions = pd.read_csv(\"data/intermediate/local_news_articles_llm_manual_exclusions.csv\")\n",
    "llm_manual_exclusions = llm_manual_exclusions[~llm_manual_exclusions[\"id\"].isin(manual_ids)]\n",
    "llm_manual_exclusions.to_csv(\"data/intermediate/local_news_articles_llm_manual_exclusions.csv\", index=False)"
   ],
   "id": "53eeb00bf883dcff",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T09:14:46.246522Z",
     "start_time": "2025-12-07T09:14:46.234822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_manual_exclusions = pd.read_csv(\"data/intermediate/local_news_articles_llm_manual_exclusions.csv\")\n",
    "news_articles_df = related_news_article_df[~related_news_article_df[\"id\"].isin(llm_manual_exclusions[\"id\"])]\n",
    "news_articles_df.to_csv(\"data/intermediate/local_news_articles.csv\", index=False)"
   ],
   "id": "9f5a91b49de2f99f",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
